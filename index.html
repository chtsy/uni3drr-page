<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Uni3DRR">
  <meta name="keywords" content="multimodal chatbot">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Uni3DRR</title>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.27.0/gradio.js"></script>
</head>


<style>
    .section {
    margin-bottom: -30px; /* Adjust this value as needed to reduce the space */
  }
  .expandable-card .card-text-container {
    max-height: 200px;
    overflow-y: hidden;
    position: relative;
  }

  .expandable-card.expanded .card-text-container {
    max-height: none;
  }

  .expand-btn {
    position: relative;
    display: none;
    background-color: rgba(255, 255, 255, 0.8);
    /* margin-top: -20px; */
    /* justify-content: center; */
    color: #510c75;
    border-color: transparent;
  }

  .expand-btn:hover {
    background-color: rgba(200, 200, 200, 0.8);
    text-decoration: none;
    border-color: transparent;
    color: #510c75;
  }

  .expand-btn:focus {
    outline: none;
    text-decoration: none;
  }

  .expandable-card:not(.expanded) .card-text-container:after {
    content: "";
    position: absolute;
    bottom: 0;
    left: 0;
    width: 100%;
    height: 90px;
    background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
  }

  .expandable-card:not(.expanded) .expand-btn {
    margin-top: -40px;
  }

  .card-body {
    padding-bottom: 5px;
  }

  .vertical-flex-layout {
    justify-content: center;
    align-items: center;
    height: 100%;
    display: flex;
    flex-direction: column;
    gap: 5px;
  }

  .figure-img {
    max-width: 100%;
    height: auto;
  }

  .adjustable-font-size {
    font-size: calc(0.5rem + 2vw);
  }

  .chat-history {
    flex-grow: 1;
    overflow-y: auto;
    /* overflow-x: hidden; */
    padding: 5px;
    border-bottom: 1px solid #ccc;
    margin-bottom: 10px;
  }

  #gradio pre {
    background-color: transparent;
  }
  
	/* ‰ΩøÁî®Ê∏êÂèòÈ¢úËâ≤ÂÆûÁé∞ÂΩ©ËôπÂ≠ó‰Ωì */
	.rainbow-text {
	  background: linear-gradient(to right, rgba(211, 242, 248, 1), rgba(246, 214, 214, 1));
	  -webkit-background-clip: text;
	  color: transparent;
	  display: inline-block;
	  font-weight: bold;
	}


    .video-container {
  display: flex;
}

.video-wrapper {
  flex: 1;
  margin: 10px;
}

.video-wrapper video {
  width: 100%;
}
</style>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><span class="rainbow-text">Uni3DR</span><sup>2</sup>:
            Unified Scene Representation and Reconstruction for 3D Large <br> Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"> <a href="https://chtsy.github.io/">Tao Chu</a><sup>1,2</sup>, </span>
            <span class="author-block"> <a href="https://panzhang0212.github.io/">Pan Zhang</a><sup>2</sup>, </span>
            <span class="author-block"> <a href="https://lightdxy.github.io/">Xiaoyi Dong</a><sup>2</sup>, </span>
            <span class="author-block"> <a href="https://yuhangzang.github.io/">Yuhang Zang</a><sup>2</sup>, </span>
            Qiong Liu<sup>1,&#9993</sup>
            <span class="author-block"> <a href="https://myownskyw7.github.io/">Jiaqi Wang</a><sup>2</sup>, </span>
          </div> 

          <div class="is-size-5 publication-authors">
            <span class="author-block" style="font-size: smaller;"> &#9993 Correspending Authors </span> 
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>South China University of Technology, </span>
            <span class="author-block"><sup>2</sup>Shanghai Artificial Intelligence Lab</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block"> <a href=""
                   class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="ai ai-arxiv"></i> </span> <span>Paper (arXiv)</span> </a> </span>
<!--              &lt;!&ndash; Demo Link. &ndash;&gt;-->
<!--              <span class="link-block"> <a href="https://www.youtube.com/"-->
<!--                   class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="fa fa-gamepad"></i> </span> <span>Demo (Hugging Face) (Coming Soon)</span> </a> </span>-->
              <!-- Code Link. -->
              <span class="link-block"> <a href="https://github.com/chtsy/uni3drr"
                   class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="fab fa-github"></i> </span> <span>Code</span> </a> </span>
          	</div>
       	  </div>
        </div>
  </div>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
	  <!--
		<div style="text-align: center;">
				<img id="teaser" width="100%" src="static/images/teaser.png">     
			  </div><br>
	  -->
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
		  <style>
			/* ‰ΩøÁî®Ê∏êÂèòÈ¢úËâ≤ÂÆûÁé∞ÂΩ©ËôπÂ≠ó‰Ωì */
			.rainbow-text {
			  background: linear-gradient(to right, rgb(27, 201, 236), rgb(137, 23, 231));
			  -webkit-background-clip: text;
			  color: transparent;
			  display: inline-block;
			  font-weight: bold;
			}
		  </style>
          <p>
            Enabling Large Language Models (LLMs) to interact with 3D environments is challenging.
            Existing approaches extract point clouds either from ground truth (GT) geometry or 3D scenes reconstructed by auxiliary models.
            Text-image aligned 2D features from CLIP are then lifted to point clouds, which serve as inputs for LLMs.
            However, this solution lacks the establishment of 3D point-to-point connections, leading to a deficiency of spatial structure information.
            Concurrently, the absence of integration and unification between the geometric and semantic representations of the scene culminates in a diminished level of 3D scene understanding.
            In this paper, we demonstrate the importance of having a unified scene representation and reconstruction framework, which is essential for LLMs in 3D scenes.
            Specifically, we introduce <span class="rainbow-text">Uni3DR</span><sup><b>2</b></sup> extracts 3D geometric and semantic aware representation features via the frozen pre-trained 2D foundation models (e.g., CLIP and SAM) and a multi-scale aggregate 3D decoder.
            Our learned 3D representations not only contribute to the reconstruction process but also provide valuable knowledge for LLMs.
            Experimental results validate that our Uni3DR<sup>2</sup> yields convincing gains over the baseline on the 3D reconstruction dataset ScanNet (increasing F-Score by +1.8\%).
            When applied to LLMs, our <span class="rainbow-text">Uni3DR</span><sup><b>2</b></sup><span class="rainbow-text">-LLM</span> exhibits superior performance over the baseline on the 3D vision-language understanding dataset ScanQA (increasing BLEU-1 by +4.0\% and +4.2\% on the val set and test set, respectively).
            Furthermore, it outperforms the state-of-the-art method that uses additional GT point clouds on both ScanQA and 3DMV-VQA.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>

<section class="section"  style="background-color:#efeff081" id="Highlight">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">
            <h2 class="title is-3">üî•Highlight</h2>
            <div class="content has-text-justified">
              <p style="font-size: 15px;">
                <ul>
				  <li>We propose Uni3DR<sup>2</sup>, a Unified Scene Representation and Reconstruction for 3D Large Language Models.</li>
				  <li>Our Uni3DR<sup>2</sup> yields convincing gains over the baseline on the 3D reconstruction dataset ScanNet (increasing F-Score by +1.8\%).</li>
				  <li>Our Uni3DR<sup>2</sup>-LLM exhibits superior performance over the baseline on the 3D vision-language understanding dataset ScanQA (increasing BLEU-1 by +4.0\% and +4.2\% on the val set and test set, respectively).
            Furthermore, it outperforms the state-of-the-art method that uses additional GT point clouds on both ScanQA and 3DMV-VQA.
          </li>
				</ul>
              </p>
            </div>
          </div>
        </div>
      </div>
</section><br>

<section class="section" id="vs">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3"> Comparison </h2>
        </div>
      </div>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
              <p>
                <b>Comparison between the representation for 3D LLMs.</b> (a) The previous baseline is isolated and complex, which requires extra NeRF, SLAM models, or depth to extract the point cloud and then lifts features to the 3D representations.
                (b) By contrast, our Uni3DR<sup>2</sup> is unified and neat. We unified learn geometric and semantically rich volumetric representation with high-quality reconstruction as LLM inputs. Our learned representation and reconstruction significantly enhance the LLM's performance in 3D environments.
                <centering>
                  <div style="text-align: center;">
                    <img id="teaser" width="80%" src="static/images/teaser.png">
                  </div>
              </p>
            </div>
            </b></font>
          </div>
        </div>
      </div>
    </section>


<section class="section" id="Uni3DRR">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3"> Uni3DR<sup>2</sup>-LLM Framework</h2>
        </div>
      </div>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
              <p>
                <b>Overview of our Uni3DR<sup>2</sup>-LLM framework.</b> Given video inputs, Uni3DR<sup>2</sup>-LLM employs
                (1) a frozen encoder integrating SAM and CLIP image encoders, followed by a decoder for 3D representations,
                (2) a light-weight module focus on \textbf{3D reconstruction}, and
                (3) an LLM integrated with QFormer for 3D vision-language understanding.
                (‚ùÑ: frozen.).
                <centering>
                  <div style="text-align: center;">
                    <img id="teaser" width="100%" src="static/images/uni3drr.png">
                  </div>
              </p>
            </div>
            </b></font>
          </div>
        </div>
      </div>
    </section>


    <section class="section" id="reconstruction">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3"> Demo of Uni3DR<sup>2</sup>-LLM </h2>
        </div>
      </div>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
              <p>
                <b>Video Demo of Reconstruction and Representation for 3D LLM.</b>
              <div class="video-container">
                <div class="video-wrapper">
                  <video controls loop muted autoplay playsinline>
                    <source src="static/video/demo1.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="video-wrapper">
                  <video controls loop muted autoplay playsinline>
                    <source src="static/video/demo3.mp4" type="video/mp4">
                  </video>
                </div>
              </div>
              <div class="video-container">
                <div class="video-wrapper">
                  <video controls loop muted autoplay playsinline>
                    <source src="static/video/demo2.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="video-wrapper">
                  <video controls loop muted autoplay playsinline>
                    <source src="static/video/demo4.mp4" type="video/mp4">
                  </video>
                </div>
              </div>

              </p>
            </div>
            </b></font>
          </div>
        </div>
      </div>
    </section>



    <section class="section" id="reconstruction">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3"> Reconstruction of Uni3DR<sup>2</sup> </h2>
        </div>
      </div>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
              <p>
                <b>3D reconstruction visualization results on ScanNet.</b>
                Compared to the baseline method (second column), our method (third column) predicts the reconstruction results with more semantic details.
                <centering>
                  <div style="text-align: center;">
                    <img id="teaser" width="100%" src="static/images/reconstruction.png">
                  </div>
              </p>
            </div>
            </b></font>
          </div>
        </div>
      </div>
    </section>


    <section class="section" id="GPT4Point-Long Caption and Question & Answering">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3"> Question and Answer of Uni3DR<sup>2</sup>-LLM </h2>
        </div>
      </div>
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
              <p>
                <b>3D vision-language understanding visualization results.</b>
                Our Uni3DR<sup>2</sup>-LLM predicts accurate reconstructions and answers the user input questions.
                <centering>
                  <div style="text-align: center;">
                    <img id="teaser" width="100%" src="static/images/qa.png">
                  </div>
              </p>
            </div>
            </b></font>
          </div>
        </div>
      </div>
    </section>


<section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>
      </code></pre>
      </div>
    </section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Thanks to <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and <a href="https://jerryxu.net/GroupViT">GroupViT</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
